{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = r\"C:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\DATA\\IITJ\\Course\\3rd Sem\\NLP\\Assignment_2\\data.csv\"  # Replace 'path_to_your_file.csv' with the actual path to your CSV file\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Read the dataset\n",
    "file_path=r\"C:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\DATA\\IITJ\\Course\\3rd Sem\\NLP\\Assignment_2\\data.csv\"\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Sentiment\"] == \"negative\", \"Sentiment\"] = 2\n",
    "data.loc[data[\"Sentiment\"] == \"neutral\", \"Sentiment\"] = 0\n",
    "data.loc[data[\"Sentiment\"] == \"positive\", \"Sentiment\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    # text = text.lower()\n",
    "    # # Remove punctuation\n",
    "    # text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the text data\n",
    "data['clean_text'] = data['Sentence'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Word Embedding Models\n",
    "# Train CBOW model\n",
    "cbow_model = Word2Vec(sentences=data['clean_text'], vector_size=100, window=5, sg=0, min_count=1, workers=4)\n",
    "\n",
    "# Train Skip-gram model\n",
    "skipgram_model = Word2Vec(sentences=data['clean_text'], vector_size=100, window=5, sg=1, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>1</td>\n",
       "      <td>[geosolutions, technology, leverage, benefon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>2</td>\n",
       "      <td>[esi, lows, 1.50, 2.50, bk, real, possibility]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[last, quarter, 2010, componenta, 's, net, sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>0</td>\n",
       "      <td>[according, finnish-russian, chamber, commerce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>0</td>\n",
       "      <td>[swedish, buyout, firm, sold, remaining, 22.4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[rising, costs, forced, packaging, producer, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nordic, walking, first, used, summer, trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>0</td>\n",
       "      <td>[according, shipping, company, viking, line, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[building, home, improvement, trade, sales, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[helsinki, afx, kci, konecranes, said, order, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     The GeoSolutions technology will leverage Bene...         1   \n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...         2   \n",
       "2     For the last quarter of 2010 , Componenta 's n...         1   \n",
       "3     According to the Finnish-Russian Chamber of Co...         0   \n",
       "4     The Swedish buyout firm has sold its remaining...         0   \n",
       "...                                                 ...       ...   \n",
       "5837  RISING costs have forced packaging producer Hu...         2   \n",
       "5838  Nordic Walking was first used as a summer trai...         0   \n",
       "5839  According shipping company Viking Line , the E...         0   \n",
       "5840  In the building and home improvement trade , s...         0   \n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...         1   \n",
       "\n",
       "                                             clean_text  \n",
       "0     [geosolutions, technology, leverage, benefon, ...  \n",
       "1        [esi, lows, 1.50, 2.50, bk, real, possibility]  \n",
       "2     [last, quarter, 2010, componenta, 's, net, sal...  \n",
       "3     [according, finnish-russian, chamber, commerce...  \n",
       "4     [swedish, buyout, firm, sold, remaining, 22.4,...  \n",
       "...                                                 ...  \n",
       "5837  [rising, costs, forced, packaging, producer, h...  \n",
       "5838  [nordic, walking, first, used, summer, trainin...  \n",
       "5839  [according, shipping, company, viking, line, e...  \n",
       "5840  [building, home, improvement, trade, sales, de...  \n",
       "5841  [helsinki, afx, kci, konecranes, said, order, ...  \n",
       "\n",
       "[5842 rows x 3 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Neural Network Model for Sentiment Analysis\n",
    "# Convert text data to numerical vectors using trained word embeddings\n",
    "def word_to_vector(text, model):\n",
    "    vector = []\n",
    "    for word in text:\n",
    "        if word in model.wv.key_to_index:\n",
    "            vector.append(model.wv[word])\n",
    "    return np.mean(vector, axis=0)\n",
    "\n",
    "data['cbow_vectors'] = data['clean_text'].apply(lambda x: word_to_vector(x, cbow_model))\n",
    "data['skipgram_vectors'] = data['clean_text'].apply(lambda x: word_to_vector(x, skipgram_model))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_cbow = np.array(data['cbow_vectors'].to_list())\n",
    "X_skipgram = np.array(data['skipgram_vectors'].to_list())\n",
    "y = data['Sentiment']\n",
    "\n",
    "X_train_cbow, X_test_cbow, y_train, y_test = train_test_split(X_cbow, y, test_size=0.2, random_state=42)\n",
    "X_train_skipgram, X_test_skipgram, _, _ = train_test_split(X_skipgram, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>cbow_vectors</th>\n",
       "      <th>skipgram_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>1</td>\n",
       "      <td>[geosolutions, technology, leverage, benefon, ...</td>\n",
       "      <td>[-0.087841325, 0.20442438, 0.057850752, -0.014...</td>\n",
       "      <td>[0.07993031, 0.23869692, 0.048818674, -0.06374...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>2</td>\n",
       "      <td>[esi, lows, 1.50, 2.50, bk, real, possibility]</td>\n",
       "      <td>[-0.017208524, 0.041779734, 0.0081582265, -0.0...</td>\n",
       "      <td>[0.019965336, 0.117266014, 0.021185737, -0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>1</td>\n",
       "      <td>[last, quarter, 2010, componenta, 's, net, sal...</td>\n",
       "      <td>[-0.24729903, 0.25635463, 0.09184723, 0.083167...</td>\n",
       "      <td>[-0.20074609, 0.27741462, 0.19301237, 0.117381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>0</td>\n",
       "      <td>[according, finnish-russian, chamber, commerce...</td>\n",
       "      <td>[-0.14599639, 0.2901071, 0.08635387, 0.0008373...</td>\n",
       "      <td>[0.060563523, 0.2579861, 0.10622661, -0.043819...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>0</td>\n",
       "      <td>[swedish, buyout, firm, sold, remaining, 22.4,...</td>\n",
       "      <td>[-0.111167245, 0.2420246, 0.06554531, -0.00958...</td>\n",
       "      <td>[-0.04758593, 0.28580222, 0.06357659, 0.021623...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[rising, costs, forced, packaging, producer, h...</td>\n",
       "      <td>[-0.055991244, 0.13617453, 0.0377705, -0.01089...</td>\n",
       "      <td>[0.029034154, 0.27089432, 0.05073889, -0.04383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nordic, walking, first, used, summer, trainin...</td>\n",
       "      <td>[-0.09274501, 0.123407364, 0.037848614, 0.0206...</td>\n",
       "      <td>[-0.02381691, 0.26700032, 0.047143266, -0.0118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>0</td>\n",
       "      <td>[according, shipping, company, viking, line, e...</td>\n",
       "      <td>[-0.10741274, 0.24980351, 0.0699953, -0.018086...</td>\n",
       "      <td>[0.01966843, 0.27589953, 0.085019514, -0.02793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[building, home, improvement, trade, sales, de...</td>\n",
       "      <td>[-0.29684648, 0.23889926, 0.11040356, 0.134824...</td>\n",
       "      <td>[-0.16992375, 0.32099146, 0.2104518, 0.0633464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[helsinki, afx, kci, konecranes, said, order, ...</td>\n",
       "      <td>[-0.07943514, 0.18688971, 0.05210115, -0.01540...</td>\n",
       "      <td>[0.071906134, 0.23397334, 0.0663146, -0.042651...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     The GeoSolutions technology will leverage Bene...         1   \n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...         2   \n",
       "2     For the last quarter of 2010 , Componenta 's n...         1   \n",
       "3     According to the Finnish-Russian Chamber of Co...         0   \n",
       "4     The Swedish buyout firm has sold its remaining...         0   \n",
       "...                                                 ...       ...   \n",
       "5837  RISING costs have forced packaging producer Hu...         2   \n",
       "5838  Nordic Walking was first used as a summer trai...         0   \n",
       "5839  According shipping company Viking Line , the E...         0   \n",
       "5840  In the building and home improvement trade , s...         0   \n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...         1   \n",
       "\n",
       "                                             clean_text  \\\n",
       "0     [geosolutions, technology, leverage, benefon, ...   \n",
       "1        [esi, lows, 1.50, 2.50, bk, real, possibility]   \n",
       "2     [last, quarter, 2010, componenta, 's, net, sal...   \n",
       "3     [according, finnish-russian, chamber, commerce...   \n",
       "4     [swedish, buyout, firm, sold, remaining, 22.4,...   \n",
       "...                                                 ...   \n",
       "5837  [rising, costs, forced, packaging, producer, h...   \n",
       "5838  [nordic, walking, first, used, summer, trainin...   \n",
       "5839  [according, shipping, company, viking, line, e...   \n",
       "5840  [building, home, improvement, trade, sales, de...   \n",
       "5841  [helsinki, afx, kci, konecranes, said, order, ...   \n",
       "\n",
       "                                           cbow_vectors  \\\n",
       "0     [-0.087841325, 0.20442438, 0.057850752, -0.014...   \n",
       "1     [-0.017208524, 0.041779734, 0.0081582265, -0.0...   \n",
       "2     [-0.24729903, 0.25635463, 0.09184723, 0.083167...   \n",
       "3     [-0.14599639, 0.2901071, 0.08635387, 0.0008373...   \n",
       "4     [-0.111167245, 0.2420246, 0.06554531, -0.00958...   \n",
       "...                                                 ...   \n",
       "5837  [-0.055991244, 0.13617453, 0.0377705, -0.01089...   \n",
       "5838  [-0.09274501, 0.123407364, 0.037848614, 0.0206...   \n",
       "5839  [-0.10741274, 0.24980351, 0.0699953, -0.018086...   \n",
       "5840  [-0.29684648, 0.23889926, 0.11040356, 0.134824...   \n",
       "5841  [-0.07943514, 0.18688971, 0.05210115, -0.01540...   \n",
       "\n",
       "                                       skipgram_vectors  \n",
       "0     [0.07993031, 0.23869692, 0.048818674, -0.06374...  \n",
       "1     [0.019965336, 0.117266014, 0.021185737, -0.018...  \n",
       "2     [-0.20074609, 0.27741462, 0.19301237, 0.117381...  \n",
       "3     [0.060563523, 0.2579861, 0.10622661, -0.043819...  \n",
       "4     [-0.04758593, 0.28580222, 0.06357659, 0.021623...  \n",
       "...                                                 ...  \n",
       "5837  [0.029034154, 0.27089432, 0.05073889, -0.04383...  \n",
       "5838  [-0.02381691, 0.26700032, 0.047143266, -0.0118...  \n",
       "5839  [0.01966843, 0.27589953, 0.085019514, -0.02793...  \n",
       "5840  [-0.16992375, 0.32099146, 0.2104518, 0.0633464...  \n",
       "5841  [0.071906134, 0.23397334, 0.0663146, -0.042651...  \n",
       "\n",
       "[5842 rows x 5 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define neural network model architecture\n",
    "def create_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4673, 100) float32\n",
      "(4673,) object\n",
      "(1169, 100) float32\n",
      "(1169,) object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(X_train_cbow.shape, X_train_cbow.dtype) for i in model.inputs]\n",
    "[print(y_train.shape, y_train.dtype) for i in model.inputs]\n",
    "[print(X_test_cbow.shape, X_test_cbow.dtype) for o in model.outputs]\n",
    "[print(y_test.shape, y_test.dtype) for o in model.outputs]\n",
    "#[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([np.array(val) for val in y_train])\n",
    "y_test = np.array([np.array(val) for val in y_test])\n",
    "\n",
    "y_train = tf.cast(y_train , dtype=tf.float32)\n",
    "y_test = tf.cast(y_test , dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranjan.patra\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3318 - loss: 0.6719 - val_accuracy: 0.4175 - val_loss: 0.6394\n",
      "Epoch 2/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3498 - loss: 0.6497 - val_accuracy: 0.3829 - val_loss: 0.6026\n",
      "Epoch 3/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3627 - loss: 0.6421 - val_accuracy: 0.4196 - val_loss: 0.6237\n",
      "Epoch 4/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3752 - loss: 0.6446 - val_accuracy: 0.3475 - val_loss: 0.5873\n",
      "Epoch 5/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3823 - loss: 0.6406 - val_accuracy: 0.3946 - val_loss: 0.5835\n",
      "Epoch 6/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3993 - loss: 0.6385 - val_accuracy: 0.3767 - val_loss: 0.5756\n",
      "Epoch 7/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3773 - loss: 0.6347 - val_accuracy: 0.3946 - val_loss: 0.5872\n",
      "Epoch 8/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3840 - loss: 0.6450 - val_accuracy: 0.3767 - val_loss: 0.5818\n",
      "Epoch 9/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3898 - loss: 0.6320 - val_accuracy: 0.3787 - val_loss: 0.5935\n",
      "Epoch 10/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3641 - loss: 0.6462 - val_accuracy: 0.3808 - val_loss: 0.5799\n",
      "Epoch 11/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3707 - loss: 0.6354 - val_accuracy: 0.3883 - val_loss: 0.5797\n",
      "Epoch 12/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4045 - loss: 0.6417 - val_accuracy: 0.3621 - val_loss: 0.5774\n",
      "Epoch 13/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3707 - loss: 0.6588 - val_accuracy: 0.4354 - val_loss: 0.5916\n",
      "Epoch 14/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3903 - loss: 0.6291 - val_accuracy: 0.3883 - val_loss: 0.5868\n",
      "Epoch 15/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3713 - loss: 0.6347 - val_accuracy: 0.3683 - val_loss: 0.5819\n",
      "Epoch 16/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3797 - loss: 0.6298 - val_accuracy: 0.3779 - val_loss: 0.5839\n",
      "Epoch 17/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3820 - loss: 0.6370 - val_accuracy: 0.4021 - val_loss: 0.5952\n",
      "Epoch 18/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3949 - loss: 0.6399 - val_accuracy: 0.3725 - val_loss: 0.5727\n",
      "Epoch 19/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3766 - loss: 0.6345 - val_accuracy: 0.4300 - val_loss: 0.6003\n",
      "Epoch 20/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4031 - loss: 0.6503 - val_accuracy: 0.3800 - val_loss: 0.5763\n",
      "Epoch 21/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4098 - loss: 0.6415 - val_accuracy: 0.4292 - val_loss: 0.5862\n",
      "Epoch 22/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3953 - loss: 0.6311 - val_accuracy: 0.3979 - val_loss: 0.5864\n",
      "Epoch 23/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4125 - loss: 0.6416 - val_accuracy: 0.4346 - val_loss: 0.5912\n",
      "Epoch 24/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3938 - loss: 0.6288 - val_accuracy: 0.4367 - val_loss: 0.5956\n",
      "Epoch 25/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3943 - loss: 0.6365 - val_accuracy: 0.3725 - val_loss: 0.5821\n",
      "Epoch 26/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3841 - loss: 0.6342 - val_accuracy: 0.4083 - val_loss: 0.5902\n",
      "Epoch 27/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3934 - loss: 0.6425 - val_accuracy: 0.3725 - val_loss: 0.5847\n",
      "Epoch 28/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3901 - loss: 0.6353 - val_accuracy: 0.3746 - val_loss: 0.5865\n",
      "Epoch 29/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3977 - loss: 0.6354 - val_accuracy: 0.3758 - val_loss: 0.5809\n",
      "Epoch 30/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3909 - loss: 0.6290 - val_accuracy: 0.4279 - val_loss: 0.5946\n",
      "Epoch 31/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4211 - loss: 0.6259 - val_accuracy: 0.3979 - val_loss: 0.5830\n",
      "Epoch 32/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3924 - loss: 0.6263 - val_accuracy: 0.3758 - val_loss: 0.5898\n",
      "Epoch 33/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4217 - loss: 0.6316 - val_accuracy: 0.4117 - val_loss: 0.5893\n",
      "Epoch 34/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4039 - loss: 0.6356 - val_accuracy: 0.3800 - val_loss: 0.5878\n",
      "Epoch 35/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3852 - loss: 0.6240 - val_accuracy: 0.4283 - val_loss: 0.5920\n",
      "Epoch 36/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4057 - loss: 0.6221 - val_accuracy: 0.3833 - val_loss: 0.5886\n",
      "Epoch 37/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3993 - loss: 0.6353 - val_accuracy: 0.3917 - val_loss: 0.5870\n",
      "Epoch 38/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3893 - loss: 0.6191 - val_accuracy: 0.4208 - val_loss: 0.6075\n",
      "Epoch 39/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3955 - loss: 0.6362 - val_accuracy: 0.3875 - val_loss: 0.5780\n",
      "Epoch 40/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3918 - loss: 0.6246 - val_accuracy: 0.4313 - val_loss: 0.6077\n",
      "Epoch 41/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4097 - loss: 0.6375 - val_accuracy: 0.3779 - val_loss: 0.5802\n",
      "Epoch 42/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3980 - loss: 0.6223 - val_accuracy: 0.4158 - val_loss: 0.5902\n",
      "Epoch 43/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 0.6273 - val_accuracy: 0.4158 - val_loss: 0.5938\n",
      "Epoch 44/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3858 - loss: 0.6339 - val_accuracy: 0.4250 - val_loss: 0.5992\n",
      "Epoch 45/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4059 - loss: 0.6341 - val_accuracy: 0.3746 - val_loss: 0.5806\n",
      "Epoch 46/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3916 - loss: 0.6351 - val_accuracy: 0.4283 - val_loss: 0.5897\n",
      "Epoch 47/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4147 - loss: 0.6400 - val_accuracy: 0.4117 - val_loss: 0.5803\n",
      "Epoch 48/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3860 - loss: 0.6317 - val_accuracy: 0.3971 - val_loss: 0.5838\n",
      "Epoch 49/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3887 - loss: 0.6329 - val_accuracy: 0.4250 - val_loss: 0.5874\n",
      "Epoch 50/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4003 - loss: 0.6241 - val_accuracy: 0.3854 - val_loss: 0.5863\n",
      "Epoch 51/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3905 - loss: 0.6227 - val_accuracy: 0.4033 - val_loss: 0.5849\n",
      "Epoch 52/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4090 - loss: 0.6225 - val_accuracy: 0.4346 - val_loss: 0.6024\n",
      "Epoch 53/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4153 - loss: 0.6335 - val_accuracy: 0.4117 - val_loss: 0.5809\n",
      "Epoch 54/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3886 - loss: 0.6310 - val_accuracy: 0.4096 - val_loss: 0.5777\n",
      "Epoch 55/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3917 - loss: 0.6463 - val_accuracy: 0.4263 - val_loss: 0.5877\n",
      "Epoch 56/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4121 - loss: 0.6492 - val_accuracy: 0.4346 - val_loss: 0.5906\n",
      "Epoch 57/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4151 - loss: 0.6324 - val_accuracy: 0.4187 - val_loss: 0.5930\n",
      "Epoch 58/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4058 - loss: 0.6287 - val_accuracy: 0.3808 - val_loss: 0.5785\n",
      "Epoch 59/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3661 - loss: 0.6384 - val_accuracy: 0.4187 - val_loss: 0.5875\n",
      "Epoch 60/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4070 - loss: 0.6419 - val_accuracy: 0.4221 - val_loss: 0.5805\n",
      "Epoch 61/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3990 - loss: 0.6258 - val_accuracy: 0.4054 - val_loss: 0.5825\n",
      "Epoch 62/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4048 - loss: 0.6405 - val_accuracy: 0.4146 - val_loss: 0.5918\n",
      "Epoch 63/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4064 - loss: 0.6250 - val_accuracy: 0.4221 - val_loss: 0.5839\n",
      "Epoch 64/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3907 - loss: 0.6323 - val_accuracy: 0.4346 - val_loss: 0.5931\n",
      "Epoch 65/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4174 - loss: 0.6110 - val_accuracy: 0.4242 - val_loss: 0.5846\n",
      "Epoch 66/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4146 - loss: 0.6252 - val_accuracy: 0.4075 - val_loss: 0.5920\n",
      "Epoch 67/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4148 - loss: 0.6244 - val_accuracy: 0.4179 - val_loss: 0.5928\n",
      "Epoch 68/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4119 - loss: 0.6360 - val_accuracy: 0.4167 - val_loss: 0.5842\n",
      "Epoch 69/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4229 - loss: 0.6335 - val_accuracy: 0.4075 - val_loss: 0.5825\n",
      "Epoch 70/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3964 - loss: 0.6284 - val_accuracy: 0.4346 - val_loss: 0.5974\n",
      "Epoch 71/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4135 - loss: 0.6221 - val_accuracy: 0.3950 - val_loss: 0.5787\n",
      "Epoch 72/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4030 - loss: 0.6374 - val_accuracy: 0.4200 - val_loss: 0.5787\n",
      "Epoch 73/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4177 - loss: 0.6198 - val_accuracy: 0.3862 - val_loss: 0.5780\n",
      "Epoch 74/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3715 - loss: 0.6369 - val_accuracy: 0.4221 - val_loss: 0.5907\n",
      "Epoch 75/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3906 - loss: 0.6309 - val_accuracy: 0.4263 - val_loss: 0.5875\n",
      "Epoch 76/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4179 - loss: 0.6344 - val_accuracy: 0.3704 - val_loss: 0.5704\n",
      "Epoch 77/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3791 - loss: 0.6037 - val_accuracy: 0.4242 - val_loss: 0.5858\n",
      "Epoch 78/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4240 - loss: 0.6316 - val_accuracy: 0.4242 - val_loss: 0.5849\n",
      "Epoch 79/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4035 - loss: 0.6272 - val_accuracy: 0.4283 - val_loss: 0.5909\n",
      "Epoch 80/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4116 - loss: 0.6305 - val_accuracy: 0.4221 - val_loss: 0.5809\n",
      "Epoch 81/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4029 - loss: 0.6295 - val_accuracy: 0.4096 - val_loss: 0.5793\n",
      "Epoch 82/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4083 - loss: 0.6039 - val_accuracy: 0.3971 - val_loss: 0.5889\n",
      "Epoch 83/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3873 - loss: 0.6215 - val_accuracy: 0.4200 - val_loss: 0.5924\n",
      "Epoch 84/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4052 - loss: 0.6149 - val_accuracy: 0.4096 - val_loss: 0.5815\n",
      "Epoch 85/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3926 - loss: 0.6455 - val_accuracy: 0.4263 - val_loss: 0.5782\n",
      "Epoch 86/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4111 - loss: 0.6282 - val_accuracy: 0.4333 - val_loss: 0.5952\n",
      "Epoch 87/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3912 - loss: 0.6303 - val_accuracy: 0.4292 - val_loss: 0.5969\n",
      "Epoch 88/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4286 - loss: 0.6129 - val_accuracy: 0.4263 - val_loss: 0.5882\n",
      "Epoch 89/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4083 - loss: 0.6293 - val_accuracy: 0.4250 - val_loss: 0.5863\n",
      "Epoch 90/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 0.6438 - val_accuracy: 0.4221 - val_loss: 0.5736\n",
      "Epoch 91/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3974 - loss: 0.6294 - val_accuracy: 0.4179 - val_loss: 0.5833\n",
      "Epoch 92/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4130 - loss: 0.6249 - val_accuracy: 0.4138 - val_loss: 0.5771\n",
      "Epoch 93/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4203 - loss: 0.6107 - val_accuracy: 0.4271 - val_loss: 0.5930\n",
      "Epoch 94/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4157 - loss: 0.6146 - val_accuracy: 0.4013 - val_loss: 0.5738\n",
      "Epoch 95/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3951 - loss: 0.6094 - val_accuracy: 0.4200 - val_loss: 0.5847\n",
      "Epoch 96/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4263 - loss: 0.6321 - val_accuracy: 0.4138 - val_loss: 0.5740\n",
      "Epoch 97/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4057 - loss: 0.6447 - val_accuracy: 0.4042 - val_loss: 0.5692\n",
      "Epoch 98/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3848 - loss: 0.6160 - val_accuracy: 0.4354 - val_loss: 0.5878\n",
      "Epoch 99/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4016 - loss: 0.6355 - val_accuracy: 0.4221 - val_loss: 0.5842\n",
      "Epoch 100/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4072 - loss: 0.6241 - val_accuracy: 0.3842 - val_loss: 0.5759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x259f211b100>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train neural network model using CBOW embeddings\n",
    "model_cbow = create_model(input_shape=(100,))\n",
    "model_cbow.fit(X_train_cbow, y_train, epochs=100, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3486 - loss: 0.6621 - val_accuracy: 0.4575 - val_loss: 0.6286\n",
      "Epoch 2/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3949 - loss: 0.6344 - val_accuracy: 0.3779 - val_loss: 0.5849\n",
      "Epoch 3/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4148 - loss: 0.6271 - val_accuracy: 0.5067 - val_loss: 0.6095\n",
      "Epoch 4/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4480 - loss: 0.6192 - val_accuracy: 0.4742 - val_loss: 0.5700\n",
      "Epoch 5/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4522 - loss: 0.6023 - val_accuracy: 0.4062 - val_loss: 0.5348\n",
      "Epoch 6/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4520 - loss: 0.5737 - val_accuracy: 0.4963 - val_loss: 0.5598\n",
      "Epoch 7/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4335 - loss: 0.5991 - val_accuracy: 0.5025 - val_loss: 0.5291\n",
      "Epoch 8/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4588 - loss: 0.5970 - val_accuracy: 0.4200 - val_loss: 0.4610\n",
      "Epoch 9/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4454 - loss: 0.5600 - val_accuracy: 0.4712 - val_loss: 0.4334\n",
      "Epoch 10/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4816 - loss: 0.5688 - val_accuracy: 0.4596 - val_loss: 0.4095\n",
      "Epoch 11/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4574 - loss: 0.5437 - val_accuracy: 0.5279 - val_loss: 0.4339\n",
      "Epoch 12/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4767 - loss: 0.5149 - val_accuracy: 0.4858 - val_loss: 0.3690\n",
      "Epoch 13/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4744 - loss: 0.5197 - val_accuracy: 0.4996 - val_loss: 0.3546\n",
      "Epoch 14/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4956 - loss: 0.5055 - val_accuracy: 0.4837 - val_loss: 0.3176\n",
      "Epoch 15/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4960 - loss: 0.5071 - val_accuracy: 0.5537 - val_loss: 0.4047\n",
      "Epoch 16/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5090 - loss: 0.4680 - val_accuracy: 0.4829 - val_loss: 0.2307\n",
      "Epoch 17/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5164 - loss: 0.4757 - val_accuracy: 0.4829 - val_loss: 0.1835\n",
      "Epoch 18/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5175 - loss: 0.4780 - val_accuracy: 0.5008 - val_loss: 0.1644\n",
      "Epoch 19/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4987 - loss: 0.4562 - val_accuracy: 0.5329 - val_loss: 0.1648\n",
      "Epoch 20/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5386 - loss: 0.4048 - val_accuracy: 0.5058 - val_loss: 0.0830\n",
      "Epoch 21/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5297 - loss: 0.4211 - val_accuracy: 0.5383 - val_loss: 0.0941\n",
      "Epoch 22/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5299 - loss: 0.3035 - val_accuracy: 0.5475 - val_loss: 0.1741\n",
      "Epoch 23/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5233 - loss: 0.3447 - val_accuracy: 0.5267 - val_loss: 0.0990\n",
      "Epoch 24/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5282 - loss: 0.3787 - val_accuracy: 0.5704 - val_loss: 0.1446\n",
      "Epoch 25/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5401 - loss: 0.3747 - val_accuracy: 0.5392 - val_loss: 0.0564\n",
      "Epoch 26/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5203 - loss: 0.3376 - val_accuracy: 0.5496 - val_loss: 0.2576\n",
      "Epoch 27/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5010 - loss: 0.3876 - val_accuracy: 0.4617 - val_loss: 0.0570\n",
      "Epoch 28/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5131 - loss: 0.2949 - val_accuracy: 0.5288 - val_loss: 0.1483\n",
      "Epoch 29/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5048 - loss: 0.3244 - val_accuracy: 0.5054 - val_loss: -0.0119\n",
      "Epoch 30/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5533 - loss: 0.3167 - val_accuracy: 0.5475 - val_loss: 0.0581\n",
      "Epoch 31/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4869 - loss: 0.3057 - val_accuracy: 0.5371 - val_loss: 0.0477\n",
      "Epoch 32/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5143 - loss: 0.3560 - val_accuracy: 0.5329 - val_loss: -0.0600\n",
      "Epoch 33/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5184 - loss: 0.2820 - val_accuracy: 0.5183 - val_loss: 0.0029\n",
      "Epoch 34/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5456 - loss: 0.2416 - val_accuracy: 0.5225 - val_loss: -0.0648\n",
      "Epoch 35/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5113 - loss: 0.2896 - val_accuracy: 0.5192 - val_loss: -0.1057\n",
      "Epoch 36/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5436 - loss: 0.3180 - val_accuracy: 0.4954 - val_loss: -0.1396\n",
      "Epoch 37/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5339 - loss: 0.2863 - val_accuracy: 0.4921 - val_loss: -0.0060\n",
      "Epoch 38/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 0.3409 - val_accuracy: 0.5621 - val_loss: 0.1610\n",
      "Epoch 39/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5324 - loss: 0.2824 - val_accuracy: 0.5308 - val_loss: -0.1005\n",
      "Epoch 40/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5443 - loss: 0.2357 - val_accuracy: 0.5308 - val_loss: 0.0026\n",
      "Epoch 41/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5416 - loss: 0.2541 - val_accuracy: 0.5579 - val_loss: 0.2219\n",
      "Epoch 42/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5041 - loss: 0.3632 - val_accuracy: 0.5275 - val_loss: 0.0292\n",
      "Epoch 43/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5230 - loss: 0.3168 - val_accuracy: 0.5433 - val_loss: -0.0601\n",
      "Epoch 44/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5408 - loss: 0.2270 - val_accuracy: 0.5350 - val_loss: -0.1199\n",
      "Epoch 45/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5227 - loss: 0.1967 - val_accuracy: 0.5321 - val_loss: -0.1870\n",
      "Epoch 46/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5579 - loss: 0.2649 - val_accuracy: 0.5379 - val_loss: -0.0930\n",
      "Epoch 47/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5136 - loss: 0.1708 - val_accuracy: 0.5588 - val_loss: 0.0667\n",
      "Epoch 48/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5389 - loss: 0.2559 - val_accuracy: 0.5108 - val_loss: -0.0882\n",
      "Epoch 49/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5287 - loss: 0.3191 - val_accuracy: 0.5246 - val_loss: -0.1678\n",
      "Epoch 50/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5368 - loss: 0.3300 - val_accuracy: 0.5454 - val_loss: -0.0035\n",
      "Epoch 51/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5405 - loss: 0.2543 - val_accuracy: 0.4892 - val_loss: -0.1894\n",
      "Epoch 52/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5239 - loss: 0.0887 - val_accuracy: 0.5392 - val_loss: -0.0393\n",
      "Epoch 53/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5286 - loss: 0.3126 - val_accuracy: 0.5496 - val_loss: -0.0482\n",
      "Epoch 54/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5251 - loss: 0.2629 - val_accuracy: 0.5433 - val_loss: -0.1727\n",
      "Epoch 55/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5399 - loss: 0.2604 - val_accuracy: 0.5213 - val_loss: -0.0754\n",
      "Epoch 56/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5410 - loss: 0.2963 - val_accuracy: 0.5392 - val_loss: -0.1721\n",
      "Epoch 57/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5428 - loss: 0.3136 - val_accuracy: 0.5350 - val_loss: -0.0232\n",
      "Epoch 58/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5475 - loss: 0.2431 - val_accuracy: 0.5496 - val_loss: -0.1562\n",
      "Epoch 59/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5457 - loss: 0.2756 - val_accuracy: 0.5662 - val_loss: -0.1385\n",
      "Epoch 60/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5666 - loss: 0.2361 - val_accuracy: 0.5537 - val_loss: -0.1197\n",
      "Epoch 61/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5482 - loss: 0.2494 - val_accuracy: 0.5171 - val_loss: -0.1354\n",
      "Epoch 62/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5390 - loss: 0.3335 - val_accuracy: 0.5496 - val_loss: -0.1670\n",
      "Epoch 63/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5445 - loss: 0.2030 - val_accuracy: 0.4692 - val_loss: 0.0680\n",
      "Epoch 64/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5219 - loss: 0.2697 - val_accuracy: 0.5150 - val_loss: -0.2286\n",
      "Epoch 65/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5458 - loss: 0.2961 - val_accuracy: 0.5371 - val_loss: -0.1481\n",
      "Epoch 66/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5438 - loss: 0.1413 - val_accuracy: 0.5350 - val_loss: -0.2212\n",
      "Epoch 67/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.2676 - val_accuracy: 0.5329 - val_loss: -0.1951\n",
      "Epoch 68/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5434 - loss: 0.1872 - val_accuracy: 0.5725 - val_loss: 0.1989\n",
      "Epoch 69/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5308 - loss: 0.1668 - val_accuracy: 0.5254 - val_loss: -0.0557\n",
      "Epoch 70/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5269 - loss: 0.2537 - val_accuracy: 0.5496 - val_loss: -0.1599\n",
      "Epoch 71/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5416 - loss: 0.1762 - val_accuracy: 0.5288 - val_loss: -0.0516\n",
      "Epoch 72/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5512 - loss: 0.2128 - val_accuracy: 0.5392 - val_loss: -0.1176\n",
      "Epoch 73/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5399 - loss: 0.2655 - val_accuracy: 0.5392 - val_loss: -0.1183\n",
      "Epoch 74/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5295 - loss: 0.2767 - val_accuracy: 0.5233 - val_loss: -0.1650\n",
      "Epoch 75/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5392 - loss: 0.1753 - val_accuracy: 0.5267 - val_loss: -0.1851\n",
      "Epoch 76/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5359 - loss: 0.2331 - val_accuracy: 0.5475 - val_loss: 0.0247\n",
      "Epoch 77/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5437 - loss: 0.2865 - val_accuracy: 0.5433 - val_loss: -0.0672\n",
      "Epoch 78/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5414 - loss: 0.2112 - val_accuracy: 0.5392 - val_loss: -0.1659\n",
      "Epoch 79/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5456 - loss: 0.3093 - val_accuracy: 0.5392 - val_loss: -0.1840\n",
      "Epoch 80/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.1980 - val_accuracy: 0.5254 - val_loss: -0.1915\n",
      "Epoch 81/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5426 - loss: 0.1909 - val_accuracy: 0.5475 - val_loss: -0.2077\n",
      "Epoch 82/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5421 - loss: 0.2597 - val_accuracy: 0.5433 - val_loss: -0.0558\n",
      "Epoch 83/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5438 - loss: 0.2762 - val_accuracy: 0.5350 - val_loss: -0.0270\n",
      "Epoch 84/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5548 - loss: 0.2843 - val_accuracy: 0.5496 - val_loss: -0.1034\n",
      "Epoch 85/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5588 - loss: 0.3391 - val_accuracy: 0.5288 - val_loss: -0.2300\n",
      "Epoch 86/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5335 - loss: 0.2353 - val_accuracy: 0.5267 - val_loss: -0.0914\n",
      "Epoch 87/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5418 - loss: 0.1957 - val_accuracy: 0.5683 - val_loss: -0.0783\n",
      "Epoch 88/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5638 - loss: 0.2838 - val_accuracy: 0.4963 - val_loss: -0.2407\n",
      "Epoch 89/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5554 - loss: 0.1070 - val_accuracy: 0.5267 - val_loss: -0.0931\n",
      "Epoch 90/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5522 - loss: 0.3089 - val_accuracy: 0.5579 - val_loss: -0.1524\n",
      "Epoch 91/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5640 - loss: 0.0986 - val_accuracy: 0.5454 - val_loss: -0.0983\n",
      "Epoch 92/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5329 - loss: 0.2479 - val_accuracy: 0.5433 - val_loss: 0.0409\n",
      "Epoch 93/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5294 - loss: 0.2677 - val_accuracy: 0.5496 - val_loss: -0.0760\n",
      "Epoch 94/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5632 - loss: 0.2329 - val_accuracy: 0.5046 - val_loss: -0.2312\n",
      "Epoch 95/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5486 - loss: 0.2374 - val_accuracy: 0.4775 - val_loss: -0.2119\n",
      "Epoch 96/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5363 - loss: 0.2619 - val_accuracy: 0.5288 - val_loss: -0.1163\n",
      "Epoch 97/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5366 - loss: 0.2472 - val_accuracy: 0.4754 - val_loss: -0.0600\n",
      "Epoch 98/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5227 - loss: 0.2082 - val_accuracy: 0.5308 - val_loss: -0.2307\n",
      "Epoch 99/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5460 - loss: 0.2296 - val_accuracy: 0.5233 - val_loss: -0.0895\n",
      "Epoch 100/100\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5607 - loss: 0.1603 - val_accuracy: 0.5433 - val_loss: -0.2186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x259f2170880>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train neural network model using Skip-gram embeddings\n",
    "model_skipgram = create_model(input_shape=(100,))\n",
    "model_skipgram.fit(X_train_skipgram, y_train, epochs=100, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Assuming binary classification with threshold 0.5\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return acc, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranjan.patra\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc_cbow, precision_cbow, recall_cbow, f1_cbow = evaluate_model(model_cbow, X_test_cbow, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranjan.patra\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc_skipgram, precision_skipgram, recall_skipgram, f1_skipgram = evaluate_model(model_skipgram, X_test_skipgram, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW Model Performance:\n",
      "Accuracy: 0.3900769888793841\n",
      "Precision: 0.4621502293983419\n",
      "Recall: 0.3900769888793841\n",
      "F1 Score: 0.3296676109036136\n",
      "\n",
      "Skip-gram Model Performance:\n",
      "Accuracy: 0.5431993156544055\n",
      "Precision: 0.5100198030889342\n",
      "Recall: 0.5431993156544055\n",
      "F1 Score: 0.5122885667166349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print evaluation results\n",
    "print(\"CBOW Model Performance:\")\n",
    "print(\"Accuracy:\", acc_cbow)\n",
    "print(\"Precision:\", precision_cbow)\n",
    "print(\"Recall:\", recall_cbow)\n",
    "print(\"F1 Score:\", f1_cbow)\n",
    "\n",
    "print(\"\\nSkip-gram Model Performance:\")\n",
    "print(\"Accuracy:\", acc_skipgram)\n",
    "print(\"Precision:\", precision_skipgram)\n",
    "print(\"Recall:\", recall_skipgram)\n",
    "print(\"F1 Score:\", f1_skipgram)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
