{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ranjanpatra/Documents/GitHub/E-Mtech/E-Mtech/.venv/lib/python3.12/site-packages (23.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement mediapipe (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for mediapipe\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ranjan.patra\\appdata\\roaming\\python\\python310\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ranjan.patra\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python) (1.23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ranjanpatra/Documents/GitHub/E-Mtech/E-Mtech/Project/ISL/MediaPipe.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ranjanpatra/Documents/GitHub/E-Mtech/E-Mtech/Project/ISL/MediaPipe.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mp_hands \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39msolutions\u001b[39m.\u001b[39mhands\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ranjanpatra/Documents/GitHub/E-Mtech/E-Mtech/Project/ISL/MediaPipe.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m hands \u001b[39m=\u001b[39m mp_hands\u001b[39m.\u001b[39mHands()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_holistic.FACEMESH_CONTOURS\n",
    "mp_holistic.FACEMESH_TESSELATION\n",
    "mp_holistic.HAND_CONNECTIONS\n",
    "mp_holistic.HandLandmark\n",
    "mp_holistic.Holistic\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"C:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\DATA\\IITJ\\Course\\Projects\\ISL\\ISL_DICTIONARY\\I\\ISL Dictionary\\A\\Alien_species.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The path does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\Git_Repos\\E-Mtech\\Project\\ISL\\MediaPipe.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ranjan.patra/OneDrive%20-%20Lingaro%20Sp.%20z%20o.%20o/Git_Repos/E-Mtech/Project/ISL/MediaPipe.ipynb#ch0000010?line=3'>4</a>\u001b[0m \u001b[39m# Initialize MediaPipe Hands\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ranjan.patra/OneDrive%20-%20Lingaro%20Sp.%20z%20o.%20o/Git_Repos/E-Mtech/Project/ISL/MediaPipe.ipynb#ch0000010?line=4'>5</a>\u001b[0m mp_hands \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39msolutions\u001b[39m.\u001b[39mhands\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ranjan.patra/OneDrive%20-%20Lingaro%20Sp.%20z%20o.%20o/Git_Repos/E-Mtech/Project/ISL/MediaPipe.ipynb#ch0000010?line=5'>6</a>\u001b[0m hands \u001b[39m=\u001b[39m mp_hands\u001b[39m.\u001b[39;49mHands()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ranjan.patra/OneDrive%20-%20Lingaro%20Sp.%20z%20o.%20o/Git_Repos/E-Mtech/Project/ISL/MediaPipe.ipynb#ch0000010?line=7'>8</a>\u001b[0m \u001b[39m# Video Capture (adjust the file path as needed)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ranjan.patra/OneDrive%20-%20Lingaro%20Sp.%20z%20o.%20o/Git_Repos/E-Mtech/Project/ISL/MediaPipe.ipynb#ch0000010?line=8'>9</a>\u001b[0m video_path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mranjan.patra\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOneDrive - Lingaro Sp. z o. o\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDATA\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mIITJ\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCourse\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mProjects\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mISL\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mISL_DICTIONARY\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mISL Dictionary\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mA\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mAlien_species.mp4\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mediapipe\\python\\solutions\\hands.py:114\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, static_image_mode, max_num_hands, model_complexity, min_detection_confidence, min_tracking_confidence)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mediapipe\\python\\solution_base.py:271\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The path does not exist."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Video Capture (adjust the file path as needed)\n",
    "video_path = r\"C:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\DATA\\IITJ\\Course\\Projects\\ISL\\ISL_DICTIONARY\\I\\ISL Dictionary\\A\\Alien_species.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the MediaPipe hands module\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Your custom processing logic here\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_index, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            print(f\"Frame {cap.get(cv2.CAP_PROP_POS_FRAMES)} - Hand {hand_index + 1}:\")\n",
    "            print(f\"Number of landmarks: {len(hand_landmarks.landmark)}\")\n",
    "\n",
    "            for landmark_index, landmark in enumerate(hand_landmarks.landmark):\n",
    "                print(f\"Landmark {landmark_index + 1}: x={landmark.x}, y={landmark.y}, z={landmark.z}\")\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Processed Frame', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Hands and Face Detection modules\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "hands = mp_hands.Hands()\n",
    "face_detection = mp_face_detection.FaceDetection()\n",
    "\n",
    "# Video Capture (adjust the file path as needed)\n",
    "video_path = r\"C:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\DATA\\IITJ\\Course\\Projects\\ISL\\ISL_DICTIONARY\\I\\ISL Dictionary\\A\\Alien_species.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the BGR image to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame using the MediaPipe hands module\n",
    "    hands_results = hands.process(rgb_frame)\n",
    "\n",
    "    # Process the frame using the MediaPipe face detection module\n",
    "    face_results = face_detection.process(rgb_frame)\n",
    "\n",
    "    # Your custom processing logic for hands\n",
    "    if hands_results.multi_hand_landmarks:\n",
    "        for hand_index, hand_landmarks in enumerate(hands_results.multi_hand_landmarks):\n",
    "            print(f\"Frame {cap.get(cv2.CAP_PROP_POS_FRAMES)} - Hand {hand_index + 1}:\")\n",
    "            print(f\"Number of landmarks: {len(hand_landmarks.landmark)}\")\n",
    "            # Additional hand processing logic if needed\n",
    "            for landmark_index, landmark in enumerate(hand_landmarks.landmark):\n",
    "                print(f\"Landmark {landmark_index + 1}: x={landmark.x}, y={landmark.y}, z={landmark.z}\")\n",
    "\n",
    "    # Your custom processing logic for faces\n",
    "    if face_results.detections:\n",
    "        for face_index, detection in enumerate(face_results.detections):\n",
    "            print(f\"Frame {cap.get(cv2.CAP_PROP_POS_FRAMES)} - Face {face_index + 1}:\")\n",
    "            print(f\"Face detection confidence: {detection.score[0]}\")\n",
    "            # Additional face processing logic if needed\n",
    "\n",
    "            for landmark_index, landmark in enumerate(hand_landmarks.landmark):\n",
    "                print(f\"Landmark {landmark_index + 1}: x={landmark.x}, y={landmark.y}, z={landmark.z}\") \n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Processed Frame', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.solutions.holistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ranjan.patra\\AppData\\Roaming\\Python\\Python310\\site-packages\\~ediapipe'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q mediapipe==0.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  hand_landmarks_list = detection_result.hand_landmarks\n",
    "  handedness_list = detection_result.handedness\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected hands to visualize.\n",
    "  for idx in range(len(hand_landmarks_list)):\n",
    "    hand_landmarks = hand_landmarks_list[idx]\n",
    "    handedness = handedness_list[idx]\n",
    "\n",
    "    # Draw the hand landmarks.\n",
    "    hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    hand_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      hand_landmarks_proto,\n",
    "      solutions.hands.HAND_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "      solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Get the top left corner of the detected hand's bounding box.\n",
    "    height, width, _ = annotated_image.shape\n",
    "    x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "    y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "    text_x = int(min(x_coordinates) * width)\n",
    "    text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "    # Draw handedness (left or right hand) on the image.\n",
    "    cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
